{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(a, dtype='float32'):\n",
    "    return np.array(a, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature-0</th>\n",
       "      <th>feature-1</th>\n",
       "      <th>feature-2</th>\n",
       "      <th>feature-3</th>\n",
       "      <th>feature-4</th>\n",
       "      <th>feature-5</th>\n",
       "      <th>feature-6</th>\n",
       "      <th>feature-7</th>\n",
       "      <th>feature-8</th>\n",
       "      <th>feature-9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature-1514</th>\n",
       "      <th>feature-1515</th>\n",
       "      <th>feature-1516</th>\n",
       "      <th>feature-1517</th>\n",
       "      <th>feature-1518</th>\n",
       "      <th>feature-1519</th>\n",
       "      <th>feature-1520</th>\n",
       "      <th>feature-1521</th>\n",
       "      <th>feature-1522</th>\n",
       "      <th>feature-1523</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.977273</td>\n",
       "      <td>6.758452</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>10.792929</td>\n",
       "      <td>160.801682</td>\n",
       "      <td>151.109783</td>\n",
       "      <td>1.791689</td>\n",
       "      <td>6.818675</td>\n",
       "      <td>8.138413</td>\n",
       "      <td>8.270161</td>\n",
       "      <td>...</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>5.658393</td>\n",
       "      <td>4.151040</td>\n",
       "      <td>4.540632</td>\n",
       "      <td>4.953183</td>\n",
       "      <td>5.351562</td>\n",
       "      <td>5.311048</td>\n",
       "      <td>5.560922</td>\n",
       "      <td>5.643015</td>\n",
       "      <td>5.715999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.408163</td>\n",
       "      <td>5.933978</td>\n",
       "      <td>2.816327</td>\n",
       "      <td>5.877551</td>\n",
       "      <td>162.949911</td>\n",
       "      <td>76.153796</td>\n",
       "      <td>1.381401</td>\n",
       "      <td>6.002651</td>\n",
       "      <td>5.080499</td>\n",
       "      <td>7.514421</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>4.830811</td>\n",
       "      <td>3.817712</td>\n",
       "      <td>4.123094</td>\n",
       "      <td>4.426343</td>\n",
       "      <td>4.823804</td>\n",
       "      <td>4.652173</td>\n",
       "      <td>4.795274</td>\n",
       "      <td>4.860781</td>\n",
       "      <td>5.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.265306</td>\n",
       "      <td>7.425645</td>\n",
       "      <td>3.734694</td>\n",
       "      <td>13.160998</td>\n",
       "      <td>172.099640</td>\n",
       "      <td>161.790879</td>\n",
       "      <td>1.603976</td>\n",
       "      <td>7.410120</td>\n",
       "      <td>10.114794</td>\n",
       "      <td>8.805738</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725693</td>\n",
       "      <td>6.397659</td>\n",
       "      <td>4.223177</td>\n",
       "      <td>4.685597</td>\n",
       "      <td>5.116870</td>\n",
       "      <td>5.333926</td>\n",
       "      <td>5.504569</td>\n",
       "      <td>5.797956</td>\n",
       "      <td>6.009581</td>\n",
       "      <td>6.200889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.976744</td>\n",
       "      <td>7.648293</td>\n",
       "      <td>3.837209</td>\n",
       "      <td>14.392765</td>\n",
       "      <td>168.885456</td>\n",
       "      <td>175.277251</td>\n",
       "      <td>1.622298</td>\n",
       "      <td>7.629033</td>\n",
       "      <td>12.180817</td>\n",
       "      <td>9.070719</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725693</td>\n",
       "      <td>5.879135</td>\n",
       "      <td>4.280132</td>\n",
       "      <td>4.563045</td>\n",
       "      <td>5.007714</td>\n",
       "      <td>5.159773</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>5.640132</td>\n",
       "      <td>5.472271</td>\n",
       "      <td>5.741399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.320988</td>\n",
       "      <td>6.534011</td>\n",
       "      <td>3.567901</td>\n",
       "      <td>8.913580</td>\n",
       "      <td>163.076959</td>\n",
       "      <td>96.019681</td>\n",
       "      <td>1.380679</td>\n",
       "      <td>6.566695</td>\n",
       "      <td>4.417010</td>\n",
       "      <td>8.058783</td>\n",
       "      <td>...</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>8.148663</td>\n",
       "      <td>4.624973</td>\n",
       "      <td>5.173321</td>\n",
       "      <td>5.720312</td>\n",
       "      <td>6.259342</td>\n",
       "      <td>6.626469</td>\n",
       "      <td>7.062406</td>\n",
       "      <td>7.472998</td>\n",
       "      <td>7.829842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.924051</td>\n",
       "      <td>6.134299</td>\n",
       "      <td>3.037975</td>\n",
       "      <td>6.506329</td>\n",
       "      <td>165.707039</td>\n",
       "      <td>82.761541</td>\n",
       "      <td>1.381957</td>\n",
       "      <td>6.187547</td>\n",
       "      <td>4.684599</td>\n",
       "      <td>7.660347</td>\n",
       "      <td>...</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>6.087556</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.820282</td>\n",
       "      <td>5.183187</td>\n",
       "      <td>5.595176</td>\n",
       "      <td>5.489454</td>\n",
       "      <td>5.604998</td>\n",
       "      <td>5.847522</td>\n",
       "      <td>5.987080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.150000</td>\n",
       "      <td>6.740695</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>10.214815</td>\n",
       "      <td>164.252922</td>\n",
       "      <td>135.639059</td>\n",
       "      <td>1.620887</td>\n",
       "      <td>6.781702</td>\n",
       "      <td>8.631090</td>\n",
       "      <td>8.248393</td>\n",
       "      <td>...</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>6.198225</td>\n",
       "      <td>4.471639</td>\n",
       "      <td>4.801970</td>\n",
       "      <td>5.237107</td>\n",
       "      <td>5.493833</td>\n",
       "      <td>5.573816</td>\n",
       "      <td>5.764799</td>\n",
       "      <td>5.865760</td>\n",
       "      <td>5.998937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.833333</td>\n",
       "      <td>6.395508</td>\n",
       "      <td>3.141026</td>\n",
       "      <td>8.717949</td>\n",
       "      <td>163.221967</td>\n",
       "      <td>94.106131</td>\n",
       "      <td>1.435936</td>\n",
       "      <td>6.443753</td>\n",
       "      <td>5.834402</td>\n",
       "      <td>7.904135</td>\n",
       "      <td>...</td>\n",
       "      <td>4.077537</td>\n",
       "      <td>6.582328</td>\n",
       "      <td>4.600158</td>\n",
       "      <td>5.032071</td>\n",
       "      <td>5.499726</td>\n",
       "      <td>5.978728</td>\n",
       "      <td>5.995208</td>\n",
       "      <td>6.179952</td>\n",
       "      <td>6.364051</td>\n",
       "      <td>6.481290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.380952</td>\n",
       "      <td>6.152543</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>6.402116</td>\n",
       "      <td>164.380868</td>\n",
       "      <td>128.391104</td>\n",
       "      <td>1.687697</td>\n",
       "      <td>6.232890</td>\n",
       "      <td>4.476844</td>\n",
       "      <td>7.736528</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.449988</td>\n",
       "      <td>3.865979</td>\n",
       "      <td>4.506730</td>\n",
       "      <td>4.765906</td>\n",
       "      <td>4.965028</td>\n",
       "      <td>3.840795</td>\n",
       "      <td>3.595598</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.228571</td>\n",
       "      <td>6.608449</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>9.180952</td>\n",
       "      <td>159.167580</td>\n",
       "      <td>180.141749</td>\n",
       "      <td>1.981354</td>\n",
       "      <td>6.690537</td>\n",
       "      <td>8.428546</td>\n",
       "      <td>8.221041</td>\n",
       "      <td>...</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>5.214936</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>4.682131</td>\n",
       "      <td>4.890349</td>\n",
       "      <td>5.192957</td>\n",
       "      <td>5.342334</td>\n",
       "      <td>5.402677</td>\n",
       "      <td>5.303305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature-0  feature-1  feature-2  feature-3   feature-4   feature-5  \\\n",
       "0  37.977273   6.758452   3.636364  10.792929  160.801682  151.109783   \n",
       "1  19.408163   5.933978   2.816327   5.877551  162.949911   76.153796   \n",
       "2  40.265306   7.425645   3.734694  13.160998  172.099640  161.790879   \n",
       "3  43.976744   7.648293   3.837209  14.392765  168.885456  175.277251   \n",
       "4  24.320988   6.534011   3.567901   8.913580  163.076959   96.019681   \n",
       "5  20.924051   6.134299   3.037975   6.506329  165.707039   82.761541   \n",
       "6  34.150000   6.740695   3.733333  10.214815  164.252922  135.639059   \n",
       "7  23.833333   6.395508   3.141026   8.717949  163.221967   94.106131   \n",
       "8  32.380952   6.152543   2.857143   6.402116  164.380868  128.391104   \n",
       "9  45.228571   6.608449   3.714286   9.180952  159.167580  180.141749   \n",
       "\n",
       "   feature-6  feature-7  feature-8  feature-9  ...  feature-1514  \\\n",
       "0   1.791689   6.818675   8.138413   8.270161  ...      3.663562   \n",
       "1   1.381401   6.002651   5.080499   7.514421  ...      3.401197   \n",
       "2   1.603976   7.410120  10.114794   8.805738  ...      3.725693   \n",
       "3   1.622298   7.629033  12.180817   9.070719  ...      3.725693   \n",
       "4   1.380679   6.566695   4.417010   8.058783  ...      4.060443   \n",
       "5   1.381957   6.187547   4.684599   7.660347  ...      3.951244   \n",
       "6   1.620887   6.781702   8.631090   8.248393  ...      3.912023   \n",
       "7   1.435936   6.443753   5.834402   7.904135  ...      4.077537   \n",
       "8   1.687697   6.232890   4.476844   7.736528  ...      2.833213   \n",
       "9   1.981354   6.690537   8.428546   8.221041  ...      3.332205   \n",
       "\n",
       "   feature-1515  feature-1516  feature-1517  feature-1518  feature-1519  \\\n",
       "0      5.658393      4.151040      4.540632      4.953183      5.351562   \n",
       "1      4.830811      3.817712      4.123094      4.426343      4.823804   \n",
       "2      6.397659      4.223177      4.685597      5.116870      5.333926   \n",
       "3      5.879135      4.280132      4.563045      5.007714      5.159773   \n",
       "4      8.148663      4.624973      5.173321      5.720312      6.259342   \n",
       "5      6.087556      4.430817      4.820282      5.183187      5.595176   \n",
       "6      6.198225      4.471639      4.801970      5.237107      5.493833   \n",
       "7      6.582328      4.600158      5.032071      5.499726      5.978728   \n",
       "8      0.000000      3.449988      3.865979      4.506730      4.765906   \n",
       "9      5.214936      3.828641      4.234107      4.682131      4.890349   \n",
       "\n",
       "   feature-1520  feature-1521  feature-1522  feature-1523  \n",
       "0      5.311048      5.560922      5.643015      5.715999  \n",
       "1      4.652173      4.795274      4.860781      5.001426  \n",
       "2      5.504569      5.797956      6.009581      6.200889  \n",
       "3      5.393628      5.640132      5.472271      5.741399  \n",
       "4      6.626469      7.062406      7.472998      7.829842  \n",
       "5      5.489454      5.604998      5.847522      5.987080  \n",
       "6      5.573816      5.764799      5.865760      5.998937  \n",
       "7      5.995208      6.179952      6.364051      6.481290  \n",
       "8      4.965028      3.840795      3.595598      0.000000  \n",
       "9      5.192957      5.342334      5.402677      5.303305  \n",
       "\n",
       "[10 rows x 1524 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "y = data.y\n",
    "X = data.drop('y', axis=1)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    790\n",
      "0.0    315\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([315.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 790.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y.value_counts())\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature-0</th>\n",
       "      <th>feature-1</th>\n",
       "      <th>feature-2</th>\n",
       "      <th>feature-3</th>\n",
       "      <th>feature-4</th>\n",
       "      <th>feature-5</th>\n",
       "      <th>feature-6</th>\n",
       "      <th>feature-7</th>\n",
       "      <th>feature-8</th>\n",
       "      <th>feature-9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature-1514</th>\n",
       "      <th>feature-1515</th>\n",
       "      <th>feature-1516</th>\n",
       "      <th>feature-1517</th>\n",
       "      <th>feature-1518</th>\n",
       "      <th>feature-1519</th>\n",
       "      <th>feature-1520</th>\n",
       "      <th>feature-1521</th>\n",
       "      <th>feature-1522</th>\n",
       "      <th>feature-1523</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.501596</td>\n",
       "      <td>1.040662</td>\n",
       "      <td>0.977455</td>\n",
       "      <td>1.355874</td>\n",
       "      <td>-0.919769</td>\n",
       "      <td>0.332058</td>\n",
       "      <td>1.131185</td>\n",
       "      <td>1.071287</td>\n",
       "      <td>1.194663</td>\n",
       "      <td>1.090206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326459</td>\n",
       "      <td>-0.177309</td>\n",
       "      <td>0.178313</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.090447</td>\n",
       "      <td>-0.094220</td>\n",
       "      <td>-0.257160</td>\n",
       "      <td>-0.176540</td>\n",
       "      <td>-0.207420</td>\n",
       "      <td>-0.176573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.408465</td>\n",
       "      <td>-0.791084</td>\n",
       "      <td>-1.029208</td>\n",
       "      <td>-0.662793</td>\n",
       "      <td>-0.367166</td>\n",
       "      <td>-0.334964</td>\n",
       "      <td>-0.465523</td>\n",
       "      <td>-0.814110</td>\n",
       "      <td>-0.071706</td>\n",
       "      <td>-0.769249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340971</td>\n",
       "      <td>-0.578221</td>\n",
       "      <td>-0.581487</td>\n",
       "      <td>-0.765109</td>\n",
       "      <td>-0.863285</td>\n",
       "      <td>-0.722424</td>\n",
       "      <td>-0.887475</td>\n",
       "      <td>-0.772615</td>\n",
       "      <td>-0.729200</td>\n",
       "      <td>-0.580862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613731</td>\n",
       "      <td>2.522972</td>\n",
       "      <td>1.218073</td>\n",
       "      <td>2.328402</td>\n",
       "      <td>1.986481</td>\n",
       "      <td>0.427107</td>\n",
       "      <td>0.400668</td>\n",
       "      <td>2.437803</td>\n",
       "      <td>2.013139</td>\n",
       "      <td>2.407961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.180819</td>\n",
       "      <td>0.342746</td>\n",
       "      <td>0.263597</td>\n",
       "      <td>0.149671</td>\n",
       "      <td>-0.115213</td>\n",
       "      <td>-0.072028</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.037094</td>\n",
       "      <td>0.097767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795627</td>\n",
       "      <td>3.017632</td>\n",
       "      <td>1.468933</td>\n",
       "      <td>2.834269</td>\n",
       "      <td>1.159675</td>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.471969</td>\n",
       "      <td>2.943593</td>\n",
       "      <td>2.868737</td>\n",
       "      <td>3.059931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>-0.070373</td>\n",
       "      <td>0.472571</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>-0.010453</td>\n",
       "      <td>-0.322511</td>\n",
       "      <td>-0.178160</td>\n",
       "      <td>-0.114873</td>\n",
       "      <td>-0.321313</td>\n",
       "      <td>-0.162202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167690</td>\n",
       "      <td>0.542018</td>\n",
       "      <td>0.809925</td>\n",
       "      <td>0.584055</td>\n",
       "      <td>-0.334484</td>\n",
       "      <td>-0.158180</td>\n",
       "      <td>-0.468331</td>\n",
       "      <td>0.489096</td>\n",
       "      <td>-0.346475</td>\n",
       "      <td>0.570120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.336087</td>\n",
       "      <td>1.029070</td>\n",
       "      <td>1.258613</td>\n",
       "      <td>1.155545</td>\n",
       "      <td>1.034877</td>\n",
       "      <td>0.986334</td>\n",
       "      <td>1.001241</td>\n",
       "      <td>0.992401</td>\n",
       "      <td>1.013248</td>\n",
       "      <td>1.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.334172</td>\n",
       "      <td>-0.346028</td>\n",
       "      <td>-0.486826</td>\n",
       "      <td>-0.404564</td>\n",
       "      <td>0.342069</td>\n",
       "      <td>-0.276163</td>\n",
       "      <td>-0.463360</td>\n",
       "      <td>-0.386914</td>\n",
       "      <td>-0.235659</td>\n",
       "      <td>-0.410207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058295</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.816046</td>\n",
       "      <td>0.509907</td>\n",
       "      <td>0.246953</td>\n",
       "      <td>0.195760</td>\n",
       "      <td>-0.086488</td>\n",
       "      <td>-0.142226</td>\n",
       "      <td>-0.071006</td>\n",
       "      <td>-0.023201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.314024</td>\n",
       "      <td>1.001210</td>\n",
       "      <td>1.214744</td>\n",
       "      <td>1.118452</td>\n",
       "      <td>-0.031983</td>\n",
       "      <td>0.194386</td>\n",
       "      <td>0.466480</td>\n",
       "      <td>0.985862</td>\n",
       "      <td>1.398695</td>\n",
       "      <td>1.036646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958521</td>\n",
       "      <td>0.084205</td>\n",
       "      <td>0.909098</td>\n",
       "      <td>0.476419</td>\n",
       "      <td>0.326049</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>-0.005782</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>-0.058841</td>\n",
       "      <td>-0.016493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.191590</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>-0.234656</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>-0.297183</td>\n",
       "      <td>-0.175209</td>\n",
       "      <td>-0.253292</td>\n",
       "      <td>0.205041</td>\n",
       "      <td>0.240507</td>\n",
       "      <td>0.189618</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379574</td>\n",
       "      <td>0.270279</td>\n",
       "      <td>1.202048</td>\n",
       "      <td>0.897227</td>\n",
       "      <td>0.711294</td>\n",
       "      <td>0.652311</td>\n",
       "      <td>0.397343</td>\n",
       "      <td>0.305390</td>\n",
       "      <td>0.273539</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.227324</td>\n",
       "      <td>-0.305495</td>\n",
       "      <td>-0.929329</td>\n",
       "      <td>-0.447363</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.129888</td>\n",
       "      <td>0.726480</td>\n",
       "      <td>-0.282149</td>\n",
       "      <td>-0.321696</td>\n",
       "      <td>-0.222769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.785868</td>\n",
       "      <td>-2.918446</td>\n",
       "      <td>-1.419692</td>\n",
       "      <td>-1.235320</td>\n",
       "      <td>-0.745362</td>\n",
       "      <td>-0.791341</td>\n",
       "      <td>-0.588182</td>\n",
       "      <td>-1.515699</td>\n",
       "      <td>-1.573124</td>\n",
       "      <td>-3.410555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.856978</td>\n",
       "      <td>0.707397</td>\n",
       "      <td>1.168134</td>\n",
       "      <td>0.693861</td>\n",
       "      <td>-1.340121</td>\n",
       "      <td>0.590408</td>\n",
       "      <td>1.869299</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>1.314816</td>\n",
       "      <td>0.969349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516482</td>\n",
       "      <td>-0.392136</td>\n",
       "      <td>-0.556574</td>\n",
       "      <td>-0.562089</td>\n",
       "      <td>-0.488061</td>\n",
       "      <td>-0.643213</td>\n",
       "      <td>-0.370132</td>\n",
       "      <td>-0.346716</td>\n",
       "      <td>-0.367734</td>\n",
       "      <td>-0.410066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature-0  feature-1  feature-2  feature-3  feature-4  feature-5  \\\n",
       "0   0.501596   1.040662   0.977455   1.355874  -0.919769   0.332058   \n",
       "1  -0.408465  -0.791084  -1.029208  -0.662793  -0.367166  -0.334964   \n",
       "2   0.613731   2.522972   1.218073   2.328402   1.986481   0.427107   \n",
       "3   0.795627   3.017632   1.468933   2.834269   1.159675   0.547120   \n",
       "4  -0.167690   0.542018   0.809925   0.584055  -0.334484  -0.158180   \n",
       "5  -0.334172  -0.346028  -0.486826  -0.404564   0.342069  -0.276163   \n",
       "6   0.314024   1.001210   1.214744   1.118452  -0.031983   0.194386   \n",
       "7  -0.191590   0.234303  -0.234656   0.503713  -0.297183  -0.175209   \n",
       "8   0.227324  -0.305495  -0.929329  -0.447363   0.000929   0.129888   \n",
       "9   0.856978   0.707397   1.168134   0.693861  -1.340121   0.590408   \n",
       "\n",
       "   feature-6  feature-7  feature-8  feature-9  ...  feature-1514  \\\n",
       "0   1.131185   1.071287   1.194663   1.090206  ...      0.326459   \n",
       "1  -0.465523  -0.814110  -0.071706  -0.769249  ...     -0.340971   \n",
       "2   0.400668   2.437803   2.013139   2.407961  ...      0.484516   \n",
       "3   0.471969   2.943593   2.868737   3.059931  ...      0.484516   \n",
       "4  -0.468331   0.489096  -0.346475   0.570120  ...      1.336087   \n",
       "5  -0.463360  -0.386914  -0.235659  -0.410207  ...      1.058295   \n",
       "6   0.466480   0.985862   1.398695   1.036646  ...      0.958521   \n",
       "7  -0.253292   0.205041   0.240507   0.189618  ...      1.379574   \n",
       "8   0.726480  -0.282149  -0.321696  -0.222769  ...     -1.785868   \n",
       "9   1.869299   0.775229   1.314816   0.969349  ...     -0.516482   \n",
       "\n",
       "   feature-1515  feature-1516  feature-1517  feature-1518  feature-1519  \\\n",
       "0     -0.177309      0.178313     -0.001516     -0.090447     -0.094220   \n",
       "1     -0.578221     -0.581487     -0.765109     -0.863285     -0.722424   \n",
       "2      0.180819      0.342746      0.263597      0.149671     -0.115213   \n",
       "3     -0.070373      0.472571      0.039474     -0.010453     -0.322511   \n",
       "4      1.029070      1.258613      1.155545      1.034877      0.986334   \n",
       "5      0.030593      0.816046      0.509907      0.246953      0.195760   \n",
       "6      0.084205      0.909098      0.476419      0.326049      0.075128   \n",
       "7      0.270279      1.202048      0.897227      0.711294      0.652311   \n",
       "8     -2.918446     -1.419692     -1.235320     -0.745362     -0.791341   \n",
       "9     -0.392136     -0.556574     -0.562089     -0.488061     -0.643213   \n",
       "\n",
       "   feature-1520  feature-1521  feature-1522  feature-1523  \n",
       "0     -0.257160     -0.176540     -0.207420     -0.176573  \n",
       "1     -0.887475     -0.772615     -0.729200     -0.580862  \n",
       "2     -0.072028      0.007996      0.037094      0.097767  \n",
       "3     -0.178160     -0.114873     -0.321313     -0.162202  \n",
       "4      1.001241      0.992401      1.013248      1.019391  \n",
       "5     -0.086488     -0.142226     -0.071006     -0.023201  \n",
       "6     -0.005782     -0.017817     -0.058841     -0.016493  \n",
       "7      0.397343      0.305390      0.273539      0.256411  \n",
       "8     -0.588182     -1.515699     -1.573124     -3.410555  \n",
       "9     -0.370132     -0.346716     -0.367734     -0.410066  \n",
       "\n",
       "[10 rows x 1524 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize(X):\n",
    "    norm = StandardScaler().fit_transform(X)\n",
    "    res = pd.DataFrame(norm, index=X.index, columns=X.columns)\n",
    "    return res\n",
    "\n",
    "X = normalize(X)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature-0</th>\n",
       "      <th>feature-1</th>\n",
       "      <th>feature-2</th>\n",
       "      <th>feature-3</th>\n",
       "      <th>feature-4</th>\n",
       "      <th>feature-5</th>\n",
       "      <th>feature-6</th>\n",
       "      <th>feature-7</th>\n",
       "      <th>feature-8</th>\n",
       "      <th>feature-9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature-1514</th>\n",
       "      <th>feature-1515</th>\n",
       "      <th>feature-1516</th>\n",
       "      <th>feature-1517</th>\n",
       "      <th>feature-1518</th>\n",
       "      <th>feature-1519</th>\n",
       "      <th>feature-1520</th>\n",
       "      <th>feature-1521</th>\n",
       "      <th>feature-1522</th>\n",
       "      <th>feature-1523</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.501596</td>\n",
       "      <td>1.040662</td>\n",
       "      <td>0.977455</td>\n",
       "      <td>1.355874</td>\n",
       "      <td>-0.919769</td>\n",
       "      <td>0.332058</td>\n",
       "      <td>1.131185</td>\n",
       "      <td>1.071287</td>\n",
       "      <td>1.194663</td>\n",
       "      <td>1.090206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326459</td>\n",
       "      <td>-0.177309</td>\n",
       "      <td>0.178313</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.090447</td>\n",
       "      <td>-0.094220</td>\n",
       "      <td>-0.257160</td>\n",
       "      <td>-0.176540</td>\n",
       "      <td>-0.207420</td>\n",
       "      <td>-0.176573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.408465</td>\n",
       "      <td>-0.791084</td>\n",
       "      <td>-1.029208</td>\n",
       "      <td>-0.662793</td>\n",
       "      <td>-0.367166</td>\n",
       "      <td>-0.334964</td>\n",
       "      <td>-0.465523</td>\n",
       "      <td>-0.814110</td>\n",
       "      <td>-0.071706</td>\n",
       "      <td>-0.769249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340971</td>\n",
       "      <td>-0.578221</td>\n",
       "      <td>-0.581487</td>\n",
       "      <td>-0.765109</td>\n",
       "      <td>-0.863285</td>\n",
       "      <td>-0.722424</td>\n",
       "      <td>-0.887475</td>\n",
       "      <td>-0.772615</td>\n",
       "      <td>-0.729200</td>\n",
       "      <td>-0.580862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613731</td>\n",
       "      <td>2.522972</td>\n",
       "      <td>1.218073</td>\n",
       "      <td>2.328402</td>\n",
       "      <td>1.986481</td>\n",
       "      <td>0.427107</td>\n",
       "      <td>0.400668</td>\n",
       "      <td>2.437803</td>\n",
       "      <td>2.013139</td>\n",
       "      <td>2.407961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.180819</td>\n",
       "      <td>0.342746</td>\n",
       "      <td>0.263597</td>\n",
       "      <td>0.149671</td>\n",
       "      <td>-0.115213</td>\n",
       "      <td>-0.072028</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.037094</td>\n",
       "      <td>0.097767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795627</td>\n",
       "      <td>3.017632</td>\n",
       "      <td>1.468933</td>\n",
       "      <td>2.834269</td>\n",
       "      <td>1.159675</td>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.471969</td>\n",
       "      <td>2.943593</td>\n",
       "      <td>2.868737</td>\n",
       "      <td>3.059931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>-0.070373</td>\n",
       "      <td>0.472571</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>-0.010453</td>\n",
       "      <td>-0.322511</td>\n",
       "      <td>-0.178160</td>\n",
       "      <td>-0.114873</td>\n",
       "      <td>-0.321313</td>\n",
       "      <td>-0.162202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167690</td>\n",
       "      <td>0.542018</td>\n",
       "      <td>0.809925</td>\n",
       "      <td>0.584055</td>\n",
       "      <td>-0.334484</td>\n",
       "      <td>-0.158180</td>\n",
       "      <td>-0.468331</td>\n",
       "      <td>0.489096</td>\n",
       "      <td>-0.346475</td>\n",
       "      <td>0.570120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.336087</td>\n",
       "      <td>1.029070</td>\n",
       "      <td>1.258613</td>\n",
       "      <td>1.155545</td>\n",
       "      <td>1.034877</td>\n",
       "      <td>0.986334</td>\n",
       "      <td>1.001241</td>\n",
       "      <td>0.992401</td>\n",
       "      <td>1.013248</td>\n",
       "      <td>1.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.334172</td>\n",
       "      <td>-0.346028</td>\n",
       "      <td>-0.486826</td>\n",
       "      <td>-0.404564</td>\n",
       "      <td>0.342069</td>\n",
       "      <td>-0.276163</td>\n",
       "      <td>-0.463360</td>\n",
       "      <td>-0.386914</td>\n",
       "      <td>-0.235659</td>\n",
       "      <td>-0.410207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058295</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.816046</td>\n",
       "      <td>0.509907</td>\n",
       "      <td>0.246953</td>\n",
       "      <td>0.195760</td>\n",
       "      <td>-0.086488</td>\n",
       "      <td>-0.142226</td>\n",
       "      <td>-0.071006</td>\n",
       "      <td>-0.023201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.314024</td>\n",
       "      <td>1.001210</td>\n",
       "      <td>1.214744</td>\n",
       "      <td>1.118452</td>\n",
       "      <td>-0.031983</td>\n",
       "      <td>0.194386</td>\n",
       "      <td>0.466480</td>\n",
       "      <td>0.985862</td>\n",
       "      <td>1.398695</td>\n",
       "      <td>1.036646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958521</td>\n",
       "      <td>0.084205</td>\n",
       "      <td>0.909098</td>\n",
       "      <td>0.476419</td>\n",
       "      <td>0.326049</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>-0.005782</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>-0.058841</td>\n",
       "      <td>-0.016493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.191590</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>-0.234656</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>-0.297183</td>\n",
       "      <td>-0.175209</td>\n",
       "      <td>-0.253292</td>\n",
       "      <td>0.205041</td>\n",
       "      <td>0.240507</td>\n",
       "      <td>0.189618</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379574</td>\n",
       "      <td>0.270279</td>\n",
       "      <td>1.202048</td>\n",
       "      <td>0.897227</td>\n",
       "      <td>0.711294</td>\n",
       "      <td>0.652311</td>\n",
       "      <td>0.397343</td>\n",
       "      <td>0.305390</td>\n",
       "      <td>0.273539</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.227324</td>\n",
       "      <td>-0.305495</td>\n",
       "      <td>-0.929329</td>\n",
       "      <td>-0.447363</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.129888</td>\n",
       "      <td>0.726480</td>\n",
       "      <td>-0.282149</td>\n",
       "      <td>-0.321696</td>\n",
       "      <td>-0.222769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.785868</td>\n",
       "      <td>-2.918446</td>\n",
       "      <td>-1.419692</td>\n",
       "      <td>-1.235320</td>\n",
       "      <td>-0.745362</td>\n",
       "      <td>-0.791341</td>\n",
       "      <td>-0.588182</td>\n",
       "      <td>-1.515699</td>\n",
       "      <td>-1.573124</td>\n",
       "      <td>-3.410555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.856978</td>\n",
       "      <td>0.707397</td>\n",
       "      <td>1.168134</td>\n",
       "      <td>0.693861</td>\n",
       "      <td>-1.340121</td>\n",
       "      <td>0.590408</td>\n",
       "      <td>1.869299</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>1.314816</td>\n",
       "      <td>0.969349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516482</td>\n",
       "      <td>-0.392136</td>\n",
       "      <td>-0.556574</td>\n",
       "      <td>-0.562089</td>\n",
       "      <td>-0.488061</td>\n",
       "      <td>-0.643213</td>\n",
       "      <td>-0.370132</td>\n",
       "      <td>-0.346716</td>\n",
       "      <td>-0.367734</td>\n",
       "      <td>-0.410066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature-0  feature-1  feature-2  feature-3  feature-4  feature-5  \\\n",
       "0   0.501596   1.040662   0.977455   1.355874  -0.919769   0.332058   \n",
       "1  -0.408465  -0.791084  -1.029208  -0.662793  -0.367166  -0.334964   \n",
       "2   0.613731   2.522972   1.218073   2.328402   1.986481   0.427107   \n",
       "3   0.795627   3.017632   1.468933   2.834269   1.159675   0.547120   \n",
       "4  -0.167690   0.542018   0.809925   0.584055  -0.334484  -0.158180   \n",
       "5  -0.334172  -0.346028  -0.486826  -0.404564   0.342069  -0.276163   \n",
       "6   0.314024   1.001210   1.214744   1.118452  -0.031983   0.194386   \n",
       "7  -0.191590   0.234303  -0.234656   0.503713  -0.297183  -0.175209   \n",
       "8   0.227324  -0.305495  -0.929329  -0.447363   0.000929   0.129888   \n",
       "9   0.856978   0.707397   1.168134   0.693861  -1.340121   0.590408   \n",
       "\n",
       "   feature-6  feature-7  feature-8  feature-9  ...  feature-1514  \\\n",
       "0   1.131185   1.071287   1.194663   1.090206  ...      0.326459   \n",
       "1  -0.465523  -0.814110  -0.071706  -0.769249  ...     -0.340971   \n",
       "2   0.400668   2.437803   2.013139   2.407961  ...      0.484516   \n",
       "3   0.471969   2.943593   2.868737   3.059931  ...      0.484516   \n",
       "4  -0.468331   0.489096  -0.346475   0.570120  ...      1.336087   \n",
       "5  -0.463360  -0.386914  -0.235659  -0.410207  ...      1.058295   \n",
       "6   0.466480   0.985862   1.398695   1.036646  ...      0.958521   \n",
       "7  -0.253292   0.205041   0.240507   0.189618  ...      1.379574   \n",
       "8   0.726480  -0.282149  -0.321696  -0.222769  ...     -1.785868   \n",
       "9   1.869299   0.775229   1.314816   0.969349  ...     -0.516482   \n",
       "\n",
       "   feature-1515  feature-1516  feature-1517  feature-1518  feature-1519  \\\n",
       "0     -0.177309      0.178313     -0.001516     -0.090447     -0.094220   \n",
       "1     -0.578221     -0.581487     -0.765109     -0.863285     -0.722424   \n",
       "2      0.180819      0.342746      0.263597      0.149671     -0.115213   \n",
       "3     -0.070373      0.472571      0.039474     -0.010453     -0.322511   \n",
       "4      1.029070      1.258613      1.155545      1.034877      0.986334   \n",
       "5      0.030593      0.816046      0.509907      0.246953      0.195760   \n",
       "6      0.084205      0.909098      0.476419      0.326049      0.075128   \n",
       "7      0.270279      1.202048      0.897227      0.711294      0.652311   \n",
       "8     -2.918446     -1.419692     -1.235320     -0.745362     -0.791341   \n",
       "9     -0.392136     -0.556574     -0.562089     -0.488061     -0.643213   \n",
       "\n",
       "   feature-1520  feature-1521  feature-1522  feature-1523  \n",
       "0     -0.257160     -0.176540     -0.207420     -0.176573  \n",
       "1     -0.887475     -0.772615     -0.729200     -0.580862  \n",
       "2     -0.072028      0.007996      0.037094      0.097767  \n",
       "3     -0.178160     -0.114873     -0.321313     -0.162202  \n",
       "4      1.001241      0.992401      1.013248      1.019391  \n",
       "5     -0.086488     -0.142226     -0.071006     -0.023201  \n",
       "6     -0.005782     -0.017817     -0.058841     -0.016493  \n",
       "7      0.397343      0.305390      0.273539      0.256411  \n",
       "8     -0.588182     -1.515699     -1.573124     -3.410555  \n",
       "9     -0.370132     -0.346716     -0.367734     -0.410066  \n",
       "\n",
       "[10 rows x 1396 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce_const_features(X):\n",
    "    res = X.nunique()\n",
    "    X.drop(res[res == 1].index, axis=1, inplace=True)\n",
    "    \n",
    "reduce_const_features(X)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature-0</th>\n",
       "      <th>feature-1</th>\n",
       "      <th>feature-2</th>\n",
       "      <th>feature-4</th>\n",
       "      <th>feature-104</th>\n",
       "      <th>feature-111</th>\n",
       "      <th>feature-112</th>\n",
       "      <th>feature-114</th>\n",
       "      <th>feature-115</th>\n",
       "      <th>feature-116</th>\n",
       "      <th>...</th>\n",
       "      <th>feature-1448</th>\n",
       "      <th>feature-1450</th>\n",
       "      <th>feature-1460</th>\n",
       "      <th>feature-1465</th>\n",
       "      <th>feature-1476</th>\n",
       "      <th>feature-1480</th>\n",
       "      <th>feature-1486</th>\n",
       "      <th>feature-1488</th>\n",
       "      <th>feature-1492</th>\n",
       "      <th>feature-1510</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.501596</td>\n",
       "      <td>1.040662</td>\n",
       "      <td>0.977455</td>\n",
       "      <td>-0.919769</td>\n",
       "      <td>0.301970</td>\n",
       "      <td>0.114540</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>-0.630219</td>\n",
       "      <td>0.425550</td>\n",
       "      <td>-0.506016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>1.239912</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.408465</td>\n",
       "      <td>-0.791084</td>\n",
       "      <td>-1.029208</td>\n",
       "      <td>-0.367166</td>\n",
       "      <td>-0.533582</td>\n",
       "      <td>-0.355543</td>\n",
       "      <td>0.395445</td>\n",
       "      <td>-1.001441</td>\n",
       "      <td>-0.064859</td>\n",
       "      <td>0.602463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>-0.668309</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613731</td>\n",
       "      <td>2.522972</td>\n",
       "      <td>1.218073</td>\n",
       "      <td>1.986481</td>\n",
       "      <td>2.328320</td>\n",
       "      <td>-0.115908</td>\n",
       "      <td>-0.244904</td>\n",
       "      <td>0.231320</td>\n",
       "      <td>0.723035</td>\n",
       "      <td>-0.241127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>3.606881</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>1.239912</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795627</td>\n",
       "      <td>3.017632</td>\n",
       "      <td>1.468933</td>\n",
       "      <td>1.159675</td>\n",
       "      <td>0.325521</td>\n",
       "      <td>1.111192</td>\n",
       "      <td>-2.141184</td>\n",
       "      <td>-1.328370</td>\n",
       "      <td>-1.568069</td>\n",
       "      <td>-0.937310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>2.229686</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>-0.668309</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167690</td>\n",
       "      <td>0.542018</td>\n",
       "      <td>0.809925</td>\n",
       "      <td>-0.334484</td>\n",
       "      <td>-0.594897</td>\n",
       "      <td>0.168392</td>\n",
       "      <td>0.039851</td>\n",
       "      <td>0.971386</td>\n",
       "      <td>0.404246</td>\n",
       "      <td>-0.587361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>-0.524705</td>\n",
       "      <td>0.195706</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>3.148133</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>2.137677</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.334172</td>\n",
       "      <td>-0.346028</td>\n",
       "      <td>-0.486826</td>\n",
       "      <td>0.342069</td>\n",
       "      <td>0.300570</td>\n",
       "      <td>-0.190200</td>\n",
       "      <td>0.262020</td>\n",
       "      <td>-0.513226</td>\n",
       "      <td>0.298825</td>\n",
       "      <td>-0.020331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>-0.524705</td>\n",
       "      <td>0.195706</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>1.239912</td>\n",
       "      <td>4.915948</td>\n",
       "      <td>2.137677</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.314024</td>\n",
       "      <td>1.001210</td>\n",
       "      <td>1.214744</td>\n",
       "      <td>-0.031983</td>\n",
       "      <td>0.150639</td>\n",
       "      <td>1.517268</td>\n",
       "      <td>-0.109521</td>\n",
       "      <td>0.027345</td>\n",
       "      <td>0.050465</td>\n",
       "      <td>-1.381715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>1.239912</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.191590</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>-0.234656</td>\n",
       "      <td>-0.297183</td>\n",
       "      <td>-0.298149</td>\n",
       "      <td>-0.203811</td>\n",
       "      <td>0.182925</td>\n",
       "      <td>-0.237650</td>\n",
       "      <td>0.543468</td>\n",
       "      <td>-0.567310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>-0.668309</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.227324</td>\n",
       "      <td>-0.305495</td>\n",
       "      <td>-0.929329</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.335926</td>\n",
       "      <td>-0.671595</td>\n",
       "      <td>-0.053309</td>\n",
       "      <td>-1.068669</td>\n",
       "      <td>0.583578</td>\n",
       "      <td>-0.294340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>-0.524705</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>-0.668309</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.856978</td>\n",
       "      <td>0.707397</td>\n",
       "      <td>1.168134</td>\n",
       "      <td>-1.340121</td>\n",
       "      <td>0.343503</td>\n",
       "      <td>0.979540</td>\n",
       "      <td>-0.048216</td>\n",
       "      <td>-0.093153</td>\n",
       "      <td>-0.271105</td>\n",
       "      <td>0.565931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198773</td>\n",
       "      <td>-0.387323</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>-0.859199</td>\n",
       "      <td>-0.264069</td>\n",
       "      <td>1.239912</td>\n",
       "      <td>-0.156062</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>-0.104781</td>\n",
       "      <td>-0.203847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature-0  feature-1  feature-2  feature-4  feature-104  feature-111  \\\n",
       "0   0.501596   1.040662   0.977455  -0.919769     0.301970     0.114540   \n",
       "1  -0.408465  -0.791084  -1.029208  -0.367166    -0.533582    -0.355543   \n",
       "2   0.613731   2.522972   1.218073   1.986481     2.328320    -0.115908   \n",
       "3   0.795627   3.017632   1.468933   1.159675     0.325521     1.111192   \n",
       "4  -0.167690   0.542018   0.809925  -0.334484    -0.594897     0.168392   \n",
       "5  -0.334172  -0.346028  -0.486826   0.342069     0.300570    -0.190200   \n",
       "6   0.314024   1.001210   1.214744  -0.031983     0.150639     1.517268   \n",
       "7  -0.191590   0.234303  -0.234656  -0.297183    -0.298149    -0.203811   \n",
       "8   0.227324  -0.305495  -0.929329   0.000929     0.335926    -0.671595   \n",
       "9   0.856978   0.707397   1.168134  -1.340121     0.343503     0.979540   \n",
       "\n",
       "   feature-112  feature-114  feature-115  feature-116  ...  feature-1448  \\\n",
       "0     0.071534    -0.630219     0.425550    -0.506016  ...     -0.198773   \n",
       "1     0.395445    -1.001441    -0.064859     0.602463  ...     -0.198773   \n",
       "2    -0.244904     0.231320     0.723035    -0.241127  ...     -0.198773   \n",
       "3    -2.141184    -1.328370    -1.568069    -0.937310  ...     -0.198773   \n",
       "4     0.039851     0.971386     0.404246    -0.587361  ...     -0.198773   \n",
       "5     0.262020    -0.513226     0.298825    -0.020331  ...     -0.198773   \n",
       "6    -0.109521     0.027345     0.050465    -1.381715  ...     -0.198773   \n",
       "7     0.182925    -0.237650     0.543468    -0.567310  ...     -0.198773   \n",
       "8    -0.053309    -1.068669     0.583578    -0.294340  ...     -0.198773   \n",
       "9    -0.048216    -0.093153    -0.271105     0.565931  ...     -0.198773   \n",
       "\n",
       "   feature-1450  feature-1460  feature-1465  feature-1476  feature-1480  \\\n",
       "0     -0.387323      0.852490     -0.859199     -0.264069      1.239912   \n",
       "1     -0.387323      0.852490     -0.859199     -0.264069     -0.668309   \n",
       "2     -0.387323      3.606881     -0.859199     -0.264069      1.239912   \n",
       "3     -0.387323      2.229686     -0.859199     -0.264069     -0.668309   \n",
       "4     -0.387323     -0.524705      0.195706     -0.264069      3.148133   \n",
       "5     -0.387323     -0.524705      0.195706     -0.264069      1.239912   \n",
       "6     -0.387323      0.852490     -0.859199     -0.264069      1.239912   \n",
       "7     -0.387323      0.852490     -0.859199     -0.264069     -0.668309   \n",
       "8     -0.387323     -0.524705     -0.859199     -0.264069     -0.668309   \n",
       "9     -0.387323      0.852490     -0.859199     -0.264069      1.239912   \n",
       "\n",
       "   feature-1486  feature-1488  feature-1492  feature-1510  \n",
       "0     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "1     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "2     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "3     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "4     -0.156062      2.137677     -0.104781     -0.203847  \n",
       "5      4.915948      2.137677     -0.104781     -0.203847  \n",
       "6     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "7     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "8     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "9     -0.156062     -0.402251     -0.104781     -0.203847  \n",
       "\n",
       "[10 rows x 245 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce_features_pearson(X, threshold=0.7):\n",
    "    pearson_coef = X.corr()\n",
    "    res = []\n",
    "    \n",
    "    for i, x in enumerate(pearson_coef.columns):\n",
    "        col = pearson_coef[x]\n",
    "        \n",
    "        for j in range(i):\n",
    "            if abs(col[j]) > threshold:\n",
    "                res.append(x)\n",
    "                break\n",
    "                \n",
    "    X.drop(res, axis=1, inplace=True)\n",
    "    \n",
    "reduce_features_pearson(X)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 245)\n",
      "(277, 245)\n",
      "(828,)\n",
      "(277,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.25)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, shuffle=True, test_size=0.5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minibatches(X, y, minibatch_size = 64):\n",
    "    shuffled_X = X.sample(frac=1)\n",
    "    shuffled_y = y.reindex(index=shuffled_X.index)\n",
    "    res = []\n",
    "    num_minibatches = X.shape[0] // minibatch_size\n",
    "    \n",
    "    for i in range(num_minibatches):\n",
    "        res.append((X.iloc[i * minibatch_size : (i + 1) * minibatch_size], y.iloc[i * minibatch_size : (i + 1) * minibatch_size]))\n",
    "        \n",
    "    if X.shape[0] % minibatch_size != 0:\n",
    "        res.append((X.iloc[num_minibatches * minibatch_size :], y.iloc[num_minibatches * minibatch_size :]))\n",
    "        \n",
    "    return res, shuffled_X, shuffled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class DFS(BaseEstimator):\n",
    "    def __init__(self, hidden_layers_sizes=[93, 93, 128, 64, 3], \n",
    "                 minibatch_size=100, learning_rate=0.1, \n",
    "                 lambda1=0., lambda2=1., \n",
    "                 alpha1=1e-3, alpha2=0.,\n",
    "                 num_epochs=1000, dropout_rate=0.25):\n",
    "        self.hidden_layers_sizes = hidden_layers_sizes\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.num_epochs = num_epochs\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "    def init_weights(n_f):\n",
    "        W = []\n",
    "        b = []\n",
    "        \n",
    "        W.append(f.get_variable('W0', shape=[n_f, self.hidden_layers_sizes[0]], initializer=tf.contrib.layers.xavier_initializer()))\n",
    "        b.append(tf.get_variable('b0', shape=[self.hidden_layers_sizes[0]], initializer=tf.zeros_initializer()))\n",
    "        \n",
    "        for i in range(1, len(self.hidden_layers_sizes)):\n",
    "            W.append(tf.get_variable('W{}'.format(i), shape=[self.hidden_layers_sizes[i-1], self.hidden_layers_sizes[i]], initializer=tf.contrib.layers.xavier_initializer()))\n",
    "            b.append(tf.get_variable('b{}'.format(i), shape=[self.hidden_layers_sizes[i]], initializer=tf.zeros_initializer()))\n",
    "            \n",
    "        return W, b\n",
    "    \n",
    "    def forward_prop(X_tf, dropout_rate_tf):\n",
    "        L = len(self.hidden_layers_sizes) + 1\n",
    "        res = X_tf * self.w\n",
    "        \n",
    "        for i in range(L - 1):\n",
    "            z = tf.matmul(res, W[i]) + b[i]\n",
    "            a = tf.nn.relu(z)\n",
    "            res = tf.nn.dropout(a, keep_prob=dropout_rate_tf)\n",
    "            \n",
    "        z = tf.matmul(res, W[L - 1]) + b[L - 1]\n",
    "        self.res = tf.nn.softmax(z)\n",
    "        \n",
    "    def elastic_net(w, l1, l2):\n",
    "        return l1 * ((1 - l2) / 2 * (tf.norm(w, 2) ** 2) + l2 * tf.norm(w, 1))\n",
    "        \n",
    "    def compute_cost(labels):\n",
    "        log_likelihood_loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.res, labels=labels))\n",
    "        w_loss = elastic_net(self.w, self.lambda1, self.lambda2)\n",
    "        W_loss = tf.reduce_sum([elastic_net(x, self.alpha1, self.alpha2) for x in W])\n",
    "        self.cost = tf.reduce_sum(log_likelihood_loss + w_loss + W_loss)\n",
    "        \n",
    "    def create_optimizer():\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def build_model(n_f):\n",
    "        tf.reset_default_graph()\n",
    "        X_tf = tf.placeholder(dtype=tf.float32, shape=[None, None], name='X')\n",
    "        y_tf = tf.placeholder(dtype=tf.float32, shape=[None], name='y')\n",
    "        dropout_rate_tf = tf.placeholder(dtype=tf.float32, shape=None, name = 'dropout_rate')\n",
    "        W, b = init_weights(n_f)\n",
    "        self.w = tf.get_variable('w', shape=[n_f], initializer=tf.ones_initializer())\n",
    "        forward_prop(X_tf, dropout_rate_tf)\n",
    "        compute_cost()\n",
    "        create_optimizer()\n",
    "        self.X_tf = X_tf\n",
    "        self.y_tf = y_tf\n",
    "        self.dropout_rate_tf = dropout_rate_tf\n",
    "        return X_tf, y_tf, dropout_rate_tf\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_tf, y_tf, dropout_rate_tf = build_model(X.shape[1])\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            self.sess = sess\n",
    "            sess.run(init)\n",
    "        \n",
    "            for i in range(self.num_epochs):\n",
    "                minibatches, shuffled_X, shuffled_y = random_minibatches(X, y)\n",
    "                epoch_cost = 0.\n",
    "\n",
    "                for minibatch in minibatches:\n",
    "                    _, cost = sess.run([self.optimizer, self.cost], feed_dict={X_tf: minibatch[0], y_tf: minibatch[1], dropout_rate_tf: self.dropout_rate})\n",
    "                    epoch_cost += cost / len(minibatches)\n",
    "                    \n",
    "                print(\"Cost after epoch {} = {}\", i, np.round(epoch_cost, 3))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.sess.run(self.res, feed_dict={self.X_tf: X, self.dropout_rate_tf: 1.}))\n",
    "    \n",
    "    def extract_features(self, X, n_f):\n",
    "        w = self.sess.run(self.w)\n",
    "        res = sorted(zip(X.columns, w), key=lambda x: abs(x[1]))\n",
    "        return [res[-i][0] for i in range(1, n_f + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp = MLP(solver='lbfgs', activation='logistic', alpha=1e-5)\n",
    "mlp_parameters = {'hidden_layer_sizes':[(100, 50)]}\n",
    "clf = GridSearchCV(mlp, mlp_parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'hidden_layer_sizes': [(100, 50)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "746     1.0\n",
      "439     1.0\n",
      "242     0.0\n",
      "655     1.0\n",
      "555     1.0\n",
      "338     1.0\n",
      "1052    1.0\n",
      "9       0.0\n",
      "599     1.0\n",
      "851     1.0\n",
      "1063    1.0\n",
      "726     1.0\n",
      "1072    1.0\n",
      "882     1.0\n",
      "94      0.0\n",
      "114     0.0\n",
      "252     0.0\n",
      "42      0.0\n",
      "601     1.0\n",
      "465     1.0\n",
      "861     1.0\n",
      "704     1.0\n",
      "745     1.0\n",
      "697     1.0\n",
      "1032    1.0\n",
      "507     1.0\n",
      "718     1.0\n",
      "120     0.0\n",
      "392     1.0\n",
      "225     0.0\n",
      "       ... \n",
      "424     1.0\n",
      "360     1.0\n",
      "646     1.0\n",
      "755     1.0\n",
      "649     1.0\n",
      "794     1.0\n",
      "985     1.0\n",
      "93      0.0\n",
      "29      0.0\n",
      "191     0.0\n",
      "442     1.0\n",
      "482     1.0\n",
      "192     0.0\n",
      "701     1.0\n",
      "571     1.0\n",
      "538     1.0\n",
      "129     0.0\n",
      "860     1.0\n",
      "849     1.0\n",
      "124     0.0\n",
      "1055    1.0\n",
      "858     1.0\n",
      "390     1.0\n",
      "321     1.0\n",
      "801     1.0\n",
      "960     1.0\n",
      "907     1.0\n",
      "541     1.0\n",
      "378     1.0\n",
      "529     1.0\n",
      "Name: y, Length: 277, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ans)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, matthews_corrcoef\n",
    "\n",
    "def calc_metrics(y_true, y_pred, dataset_name='test'):\n",
    "    print('Accuracy score for {} set: {}'.format(dataset_name, np.round(accuracy_score(y_true, y_pred), 3)))\n",
    "    print('F1 score for {} set: {}'.format(dataset_name, np.round(f1_score(y_true, y_pred), 3)))\n",
    "    print('Matthews corr coef score for {} set: {}'.format(dataset_name, np.round(matthews_corrcoef(y_true, y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test set: 0.834\n",
      "F1 score for test set: 0.887\n",
      "Matthews corr coef score for test set: 0.577\n"
     ]
    }
   ],
   "source": [
    "calc_metrics(y_test, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
